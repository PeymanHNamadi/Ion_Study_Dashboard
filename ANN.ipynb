{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import preprocessing\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importing the dataset\n",
    "### You need to change Ion and data path to simulate ion constituents. Ion = '##' & df = pd.read_csv(##_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Long Station Name</th>\n",
       "      <th>Collection Date</th>\n",
       "      <th>EC</th>\n",
       "      <th>Alkalinity</th>\n",
       "      <th>Sacramento X2</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>WYT</th>\n",
       "      <th>Data</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Old River near Rock Slough</td>\n",
       "      <td>1959-06-19</td>\n",
       "      <td>318.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>91.438186</td>\n",
       "      <td>OMR</td>\n",
       "      <td>Interior</td>\n",
       "      <td>BN</td>\n",
       "      <td>TT</td>\n",
       "      <td>June</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Old River near Rock Slough</td>\n",
       "      <td>1959-06-19</td>\n",
       "      <td>327.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>91.438186</td>\n",
       "      <td>OMR</td>\n",
       "      <td>Interior</td>\n",
       "      <td>BN</td>\n",
       "      <td>TT</td>\n",
       "      <td>June</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Old River near Rock Slough</td>\n",
       "      <td>1959-07-07</td>\n",
       "      <td>716.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>94.298896</td>\n",
       "      <td>OMR</td>\n",
       "      <td>Interior</td>\n",
       "      <td>BN</td>\n",
       "      <td>TT</td>\n",
       "      <td>July</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Old River near Rock Slough</td>\n",
       "      <td>1959-07-07</td>\n",
       "      <td>749.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>94.298896</td>\n",
       "      <td>OMR</td>\n",
       "      <td>Interior</td>\n",
       "      <td>BN</td>\n",
       "      <td>TT</td>\n",
       "      <td>July</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Old River near Rock Slough</td>\n",
       "      <td>1959-07-21</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>95.924951</td>\n",
       "      <td>OMR</td>\n",
       "      <td>Interior</td>\n",
       "      <td>BN</td>\n",
       "      <td>TT</td>\n",
       "      <td>July</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>PDUP</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>908.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>SouthDelta</td>\n",
       "      <td>Interior</td>\n",
       "      <td>D</td>\n",
       "      <td>NCRO</td>\n",
       "      <td>April</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>TWA</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>676.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>SouthDelta</td>\n",
       "      <td>Interior</td>\n",
       "      <td>D</td>\n",
       "      <td>NCRO</td>\n",
       "      <td>April</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>PDUP</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>SouthDelta</td>\n",
       "      <td>Interior</td>\n",
       "      <td>D</td>\n",
       "      <td>NCRO</td>\n",
       "      <td>May</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>ORX</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>254.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>SouthDelta</td>\n",
       "      <td>Interior</td>\n",
       "      <td>D</td>\n",
       "      <td>NCRO</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>PDUP</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>SouthDelta</td>\n",
       "      <td>Interior</td>\n",
       "      <td>D</td>\n",
       "      <td>NCRO</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Long Station Name Collection Date      EC  Alkalinity  \\\n",
       "0     Old River near Rock Slough      1959-06-19   318.0        76.0   \n",
       "1     Old River near Rock Slough      1959-06-19   327.0        73.0   \n",
       "2     Old River near Rock Slough      1959-07-07   716.0        74.0   \n",
       "3     Old River near Rock Slough      1959-07-07   749.0        73.0   \n",
       "4     Old River near Rock Slough      1959-07-21  1320.0        69.0   \n",
       "...                          ...             ...     ...         ...   \n",
       "1034                        PDUP      2020-04-29   908.0       110.0   \n",
       "1035                         TWA      2020-04-29   676.0        98.0   \n",
       "1036                        PDUP      2020-05-18  1540.0       166.0   \n",
       "1037                         ORX      2020-06-16   254.0        50.0   \n",
       "1038                        PDUP      2020-06-17  1410.0       155.0   \n",
       "\n",
       "      Sacramento X2    Location      Area WYT  Data  month  year  \n",
       "0         91.438186         OMR  Interior  BN    TT   June  1959  \n",
       "1         91.438186         OMR  Interior  BN    TT   June  1959  \n",
       "2         94.298896         OMR  Interior  BN    TT   July  1959  \n",
       "3         94.298896         OMR  Interior  BN    TT   July  1959  \n",
       "4         95.924951         OMR  Interior  BN    TT   July  1959  \n",
       "...             ...         ...       ...  ..   ...    ...   ...  \n",
       "1034      75.000000  SouthDelta  Interior   D  NCRO  April  2020  \n",
       "1035      75.000000  SouthDelta  Interior   D  NCRO  April  2020  \n",
       "1036      81.000000  SouthDelta  Interior   D  NCRO    May  2020  \n",
       "1037      80.000000  SouthDelta  Interior   D  NCRO   June  2020  \n",
       "1038      80.000000  SouthDelta  Interior   D  NCRO   June  2020  \n",
       "\n",
       "[1039 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ion_types = [\"Alkalinity\", \"Br\", \"Ca\", \"Cl\", \"K\", \"Mg\", \"Na\", \"SO4\" \"TDS\"]\n",
    "paths = [f\"inputs/{ion_type}.csv\" for ion_type in ion_types]\n",
    "\n",
    "Ion = 'Alkalinity'\n",
    "\n",
    "df = pd.read_csv(f'inputs/{Ion}.csv')\n",
    "df = pd.DataFrame(df)\n",
    "df[\"Collection Date\"] = pd.to_datetime(df[\"Collection Date\"])\n",
    "df[\"Long Station Name\"] = df[\"Long Station Name\"].astype(\"category\")\n",
    "df[\"Location\"] = df[\"Location\"].astype(\"category\")\n",
    "df[\"Area\"] = df[\"Area\"].astype(\"category\")\n",
    "df[\"month\"] = df[\"Collection Date\"].dt.month_name()\n",
    "df[\"month\"] = df[\"month\"].astype(\"category\")\n",
    "df[\"year\"] = df[\"Collection Date\"].dt.year\n",
    "df[\"year\"] = df[\"year\"].astype(\"category\")\n",
    "df[\"year\"] = df[\"year\"].astype(\"category\")\n",
    "df[\"WYT\"] = df[\"WYT\"].astype(\"category\")\n",
    "df[\"EC\"] = df[\"EC\"].astype(\"float64\")\n",
    "df[Ion] = df[Ion].astype(\"float64\")\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Splitting the dataset into the Training set and Test set\n",
    "### &\n",
    "## Feature Scaling\n",
    "\n",
    "### In this study, Training and Test datasets were randomly selected (20% Test & 80% Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape= (1039, 11)\n",
      "dfmerged.shape= (1039, 31)\n",
      "X.shape= (1039, 22)\n",
      "XD.shape= (1039, 20)\n",
      "X_Train.shape= (831, 22)\n",
      "y_Train.shape= (831,)\n",
      "X_Test.shape= (208, 22)\n",
      "y_Test.shape= (208,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Long Station Name</th>\n",
       "      <th>Collection Date</th>\n",
       "      <th>EC</th>\n",
       "      <th>Alkalinity</th>\n",
       "      <th>Sacramento X2</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>WYT</th>\n",
       "      <th>Data</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>December</th>\n",
       "      <th>February</th>\n",
       "      <th>January</th>\n",
       "      <th>July</th>\n",
       "      <th>June</th>\n",
       "      <th>March</th>\n",
       "      <th>May</th>\n",
       "      <th>November</th>\n",
       "      <th>October</th>\n",
       "      <th>September</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Old River near Rock Slough</td>\n",
       "      <td>1959-06-19</td>\n",
       "      <td>318.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>91.438186</td>\n",
       "      <td>OMR</td>\n",
       "      <td>Interior</td>\n",
       "      <td>BN</td>\n",
       "      <td>TT</td>\n",
       "      <td>June</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Old River near Rock Slough</td>\n",
       "      <td>1959-06-19</td>\n",
       "      <td>327.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>91.438186</td>\n",
       "      <td>OMR</td>\n",
       "      <td>Interior</td>\n",
       "      <td>BN</td>\n",
       "      <td>TT</td>\n",
       "      <td>June</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Old River near Rock Slough</td>\n",
       "      <td>1959-07-07</td>\n",
       "      <td>716.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>94.298896</td>\n",
       "      <td>OMR</td>\n",
       "      <td>Interior</td>\n",
       "      <td>BN</td>\n",
       "      <td>TT</td>\n",
       "      <td>July</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Old River near Rock Slough</td>\n",
       "      <td>1959-07-07</td>\n",
       "      <td>749.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>94.298896</td>\n",
       "      <td>OMR</td>\n",
       "      <td>Interior</td>\n",
       "      <td>BN</td>\n",
       "      <td>TT</td>\n",
       "      <td>July</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Old River near Rock Slough</td>\n",
       "      <td>1959-07-21</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>95.924951</td>\n",
       "      <td>OMR</td>\n",
       "      <td>Interior</td>\n",
       "      <td>BN</td>\n",
       "      <td>TT</td>\n",
       "      <td>July</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>PDUP</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>908.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>SouthDelta</td>\n",
       "      <td>Interior</td>\n",
       "      <td>D</td>\n",
       "      <td>NCRO</td>\n",
       "      <td>April</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>TWA</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>676.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>SouthDelta</td>\n",
       "      <td>Interior</td>\n",
       "      <td>D</td>\n",
       "      <td>NCRO</td>\n",
       "      <td>April</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>PDUP</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>SouthDelta</td>\n",
       "      <td>Interior</td>\n",
       "      <td>D</td>\n",
       "      <td>NCRO</td>\n",
       "      <td>May</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>ORX</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>254.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>SouthDelta</td>\n",
       "      <td>Interior</td>\n",
       "      <td>D</td>\n",
       "      <td>NCRO</td>\n",
       "      <td>June</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>PDUP</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>SouthDelta</td>\n",
       "      <td>Interior</td>\n",
       "      <td>D</td>\n",
       "      <td>NCRO</td>\n",
       "      <td>June</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1039 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Long Station Name Collection Date      EC  Alkalinity  \\\n",
       "0     Old River near Rock Slough      1959-06-19   318.0        76.0   \n",
       "1     Old River near Rock Slough      1959-06-19   327.0        73.0   \n",
       "2     Old River near Rock Slough      1959-07-07   716.0        74.0   \n",
       "3     Old River near Rock Slough      1959-07-07   749.0        73.0   \n",
       "4     Old River near Rock Slough      1959-07-21  1320.0        69.0   \n",
       "...                          ...             ...     ...         ...   \n",
       "1034                        PDUP      2020-04-29   908.0       110.0   \n",
       "1035                         TWA      2020-04-29   676.0        98.0   \n",
       "1036                        PDUP      2020-05-18  1540.0       166.0   \n",
       "1037                         ORX      2020-06-16   254.0        50.0   \n",
       "1038                        PDUP      2020-06-17  1410.0       155.0   \n",
       "\n",
       "      Sacramento X2    Location      Area WYT  Data  month  ... December  \\\n",
       "0         91.438186         OMR  Interior  BN    TT   June  ...      0.0   \n",
       "1         91.438186         OMR  Interior  BN    TT   June  ...      0.0   \n",
       "2         94.298896         OMR  Interior  BN    TT   July  ...      0.0   \n",
       "3         94.298896         OMR  Interior  BN    TT   July  ...      0.0   \n",
       "4         95.924951         OMR  Interior  BN    TT   July  ...      0.0   \n",
       "...             ...         ...       ...  ..   ...    ...  ...      ...   \n",
       "1034      75.000000  SouthDelta  Interior   D  NCRO  April  ...      0.0   \n",
       "1035      75.000000  SouthDelta  Interior   D  NCRO  April  ...      0.0   \n",
       "1036      81.000000  SouthDelta  Interior   D  NCRO    May  ...      0.0   \n",
       "1037      80.000000  SouthDelta  Interior   D  NCRO   June  ...      0.0   \n",
       "1038      80.000000  SouthDelta  Interior   D  NCRO   June  ...      0.0   \n",
       "\n",
       "      February  January  July  June  March  May  November  October  September  \n",
       "0          0.0      0.0   0.0   1.0    0.0  0.0       0.0      0.0        0.0  \n",
       "1          0.0      0.0   0.0   1.0    0.0  0.0       0.0      0.0        0.0  \n",
       "2          0.0      0.0   1.0   0.0    0.0  0.0       0.0      0.0        0.0  \n",
       "3          0.0      0.0   1.0   0.0    0.0  0.0       0.0      0.0        0.0  \n",
       "4          0.0      0.0   1.0   0.0    0.0  0.0       0.0      0.0        0.0  \n",
       "...        ...      ...   ...   ...    ...  ...       ...      ...        ...  \n",
       "1034       0.0      0.0   0.0   0.0    0.0  0.0       0.0      0.0        0.0  \n",
       "1035       0.0      0.0   0.0   0.0    0.0  0.0       0.0      0.0        0.0  \n",
       "1036       0.0      0.0   0.0   0.0    0.0  1.0       0.0      0.0        0.0  \n",
       "1037       0.0      0.0   0.0   1.0    0.0  0.0       0.0      0.0        0.0  \n",
       "1038       0.0      0.0   0.0   1.0    0.0  0.0       0.0      0.0        0.0  \n",
       "\n",
       "[1039 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "ohe = OneHotEncoder()\n",
    "feature_array = ohe.fit_transform(df[['WYT','Location','month']]).toarray()\n",
    "feature_labels = ohe.categories_\n",
    "feature_labels = np.concatenate((feature_labels[0], feature_labels[1],feature_labels[2]))\n",
    "XD = pd.DataFrame(feature_array,columns=feature_labels)\n",
    "dfmerged=pd.merge(df,XD, left_index=True, right_index=True)\n",
    "dfmerged.dropna(subset=[\"Sacramento X2\"], inplace=True)\n",
    "# dfmerged=dfmerged.loc[:, ['EC', 'Sacramento X2',Ion, 'AN', 'BN', 'C', 'D', 'W', 'OMR','SJRcorridor', 'SouthDelta', 'April', 'August', 'December', 'February','January', 'July', 'June', 'March',\n",
    "#  'May', 'November', 'October','September']]\n",
    "X = dfmerged.loc[:, ['EC', 'Sacramento X2', 'AN', 'BN', 'C', 'D', 'W', 'OMR','SJRcorridor', 'SouthDelta', 'April', 'August', 'December', 'February','January', 'July', 'June', 'March','May', 'November', 'October','September']]\n",
    "y=dfmerged.iloc[:, 3]\n",
    "\n",
    "X2=X\n",
    "\n",
    "X2['EC']=(X2['EC'] -50)/(3500-50)\n",
    "X2['Sacramento X2']=(X2['Sacramento X2'] -0)/(100-0)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X2, y, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "print('df.shape=',df.shape)\n",
    "print('dfmerged.shape=',dfmerged.shape)\n",
    "print('X.shape=',X.shape)\n",
    "print('XD.shape=',XD.shape)\n",
    "print('X_Train.shape=',X_train.shape)\n",
    "print('y_Train.shape=',y_train.shape)\n",
    "print('X_Test.shape=',X_test.shape)\n",
    "print('y_Test.shape=',y_test.shape)\n",
    "dfmerged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Alternative Models\n",
    "### 1- Multiple Linear Regression (MLR), 2- Regression Trees (RT), 3- Random Forest (RF), 4- Gradient Boosting (GB),  5- Artificial Neural Networks (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alkalinity\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "regressorLinear = LinearRegression()\n",
    "regressorTree = DecisionTreeRegressor(random_state=0, min_samples_leaf=4)\n",
    "regressorRF = RandomForestRegressor(n_estimators=100, min_samples_leaf=3, random_state=0)\n",
    "regressorGB = GradientBoostingRegressor(min_samples_leaf=4)\n",
    "\n",
    "\n",
    "print(Ion)\n",
    "\n",
    "regressorLinear.fit(X_train, y_train)\n",
    "y_pred_test = regressorLinear.predict(X_test)\n",
    "y_pred_train = regressorLinear.predict(X_train)\n",
    "y_pred_LR = regressorLinear.predict(X)\n",
    "y_pred_test_LR = regressorLinear.predict(X_test)\n",
    "# print(\"LinearRegression:\")\n",
    "# print(\"        \", \"Training\", \"R2 =\", round(r2_score(y_train, y_pred_train), ndigits=2), \"  MAE =\", round(\n",
    "#     mean_absolute_error(y_train, y_pred_train), ndigits=2), \"  MSE =\", round(mean_squared_error(y_train, y_pred_train), ndigits=2))\n",
    "# print(\"        \", \"Test    \", \"R2 =\", round(r2_score(y_test, y_pred_test), ndigits=2), \"  MAE =\", round(\n",
    "#     mean_absolute_error(y_test, y_pred_test), ndigits=2), \"  MSE =\", round(mean_squared_error(y_test, y_pred_test), ndigits=2))\n",
    "\n",
    "\n",
    "# print(\"        \")\n",
    "\n",
    "regressorTree.fit(X_train, y_train)\n",
    "y_pred_test = regressorTree.predict(X_test)\n",
    "y_pred_train = regressorTree.predict(X_train)\n",
    "y_pred_RT = regressorTree.predict(X)\n",
    "y_pred_test_RT = regressorTree.predict(X_test)\n",
    "# print(\"DecisionTreeRegressor:\")\n",
    "# print(\"        \", \"Training\", \"R2 =\", round(r2_score(y_train, y_pred_train), ndigits=2), \"  MAE =\", round(\n",
    "#     mean_absolute_error(y_train, y_pred_train), ndigits=2), \"  MSE =\", round(mean_squared_error(y_train, y_pred_train), ndigits=2))\n",
    "# print(\"        \", \"Test    \", \"R2 =\", round(r2_score(y_test, y_pred_test), ndigits=2), \"  MAE =\", round(\n",
    "#     mean_absolute_error(y_test, y_pred_test), ndigits=2), \"  MSE =\", round(mean_squared_error(y_test, y_pred_test), ndigits=2))\n",
    "\n",
    "# print(\"        \")\n",
    "\n",
    "regressorRF.fit(X_train, y_train)\n",
    "y_pred_test = regressorRF.predict(X_test)\n",
    "y_pred_train = regressorRF.predict(X_train)\n",
    "y_pred_RF = regressorRF.predict(X)\n",
    "y_pred_test_RF = regressorRF.predict(X_test)\n",
    "# print(\"Random Forest:\")\n",
    "# print(\"        \", \"Training\", \"R2 =\", round(r2_score(y_train, y_pred_train), ndigits=2), \"  MAE =\", round(\n",
    "#     mean_absolute_error(y_train, y_pred_train), ndigits=2), \"  MSE =\", round(mean_squared_error(y_train, y_pred_train), ndigits=2))\n",
    "# print(\"        \", \"Test    \", \"R2 =\", round(r2_score(y_test, y_pred_test), ndigits=2), \"  MAE =\", round(\n",
    "#     mean_absolute_error(y_test, y_pred_test), ndigits=2), \"  MSE =\", round(mean_squared_error(y_test, y_pred_test), ndigits=2))\n",
    "\n",
    "print(\"        \")\n",
    "\n",
    "regressorGB.fit(X_train, y_train)\n",
    "y_pred_test = regressorGB.predict(X_test)\n",
    "y_pred_train = regressorGB.predict(X_train)\n",
    "y_pred_GB = regressorGB.predict(X)\n",
    "y_pred_test_GB = regressorGB.predict(X_test)\n",
    "# print(\"GradientBoosting:\")\n",
    "# print(\"        \", \"Training\", \"R2 =\", round(r2_score(y_train, y_pred_train), ndigits=2), \"  MAE =\", round(\n",
    "#     mean_absolute_error(y_train, y_pred_train), ndigits=2), \"  MSE =\", round(mean_squared_error(y_train, y_pred_train), ndigits=2))\n",
    "# print(\"        \", \"Test    \", \"R2 =\", round(r2_score(y_test, y_pred_test), ndigits=2), \"  MAE =\", round(\n",
    "#     mean_absolute_error(y_test, y_pred_test), ndigits=2), \"  MSE =\", round(mean_squared_error(y_test, y_pred_test), ndigits=2))\n",
    "\n",
    "# print(\"        \")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Ion==\"TDS\":\n",
    "    N=[30,30,20,30]\n",
    "    A=['elu','sigmoid','elu','relu']\n",
    "elif Ion == \"Mg\":\n",
    "    N=[30,30,20,30]\n",
    "    A=['relu','elu','tanh','relu']\n",
    "elif Ion == \"Na\":\n",
    "    N=[30,30,20,30]\n",
    "    A=['tanh','elu','sigmoid','elu']\n",
    "elif Ion == \"Ca\":\n",
    "    N=[40,40,40,30]\n",
    "    A=['elu','sigmoid','relu','tanh']\n",
    "elif Ion == \"Cl\":\n",
    "    N=[30,20,30,30]\n",
    "    A=['relu','elu','sigmoid','elu']\n",
    "elif Ion == \"SO4\":\n",
    "    N=[44,44,44,22]\n",
    "    A=['relu','relu','relu','relu']\n",
    "elif Ion == \"Br\":\n",
    "    N=[20,20,20,20]\n",
    "    A=['elu','sigmoid','elu','tanh']\n",
    "elif Ion == \"Alkalinity\":\n",
    "    N=[30,30,30,30]\n",
    "    A=['tanh','relu','tanh','elu']\n",
    "elif Ion == \"K\":\n",
    "    N=[44,44,44,22]\n",
    "    A=['relu','relu','relu','relu']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "Alkalinity Training R2 = 0.91   MAE = 5.85   MSE = 71.52\n",
      "Alkalinity Test     R2 = 0.85   MAE = 7.38   MSE = 96.28\n"
     ]
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"tf_training_logs\")\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(root_logdir)\n",
    "\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=22))\n",
    "ann.add(tf.keras.layers.Dense(units=N[0], activation=A[0]))\n",
    "ann.add(tf.keras.layers.Dense(units=N[1], activation=A[1]))\n",
    "ann.add(tf.keras.layers.Dense(units=N[2], activation=A[2]))\n",
    "ann.add(tf.keras.layers.Dense(units=N[3], activation=A[3]))\n",
    "ann.add(tf.keras.layers.Dense(units=1))\n",
    "ann.compile(optimizer=keras.optimizers.Adamax(learning_rate=0.001), loss=\"mean_absolute_error\", metrics=['mean_absolute_error'])\n",
    "history = ann.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[keras.callbacks.EarlyStopping( monitor=\"val_loss\", patience=100, mode=\"min\", restore_best_weights=True),tensorboard_cb],batch_size=32, epochs=5000, verbose=0)\n",
    "\n",
    "\n",
    "y_pred_test = ann.predict(X_test)\n",
    "y_pred_train = ann.predict(X_train)\n",
    "\n",
    "print(Ion, \"Training\", \"R2 =\", round(r2_score(y_train, y_pred_train), ndigits=2), \"  MAE =\", round(mean_absolute_error(\n",
    "    y_train, y_pred_train), ndigits=2), \"  MSE =\", round(mean_squared_error(y_train, y_pred_train), ndigits=2))\n",
    "print(Ion, \"Test    \", \"R2 =\", round(r2_score(y_test, y_pred_test), ndigits=2),  \"  MAE =\", round(mean_absolute_error(\n",
    "    y_test, y_pred_test), ndigits=2),  \"  MSE =\", round(mean_squared_error(y_test, y_pred_test), ndigits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1000us/step\n",
      "26/26 [==============================] - 0s 1000us/step\n",
      "Alkalinity Training R2 = 0.91   MAE = 5.68   MSE = 67.78\n",
      "Alkalinity Test     R2 = 0.86   MAE = 7.23   MSE = 89.51\n"
     ]
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"tf_training_logs\")\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(root_logdir)\n",
    "\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=22))\n",
    "ann.add(tf.keras.layers.Dense(units=44,  activation='sigmoid'))\n",
    "ann.add(tf.keras.layers.Dense(units=88, activation= 'elu'))\n",
    "ann.add(tf.keras.layers.Dense(units=44, activation= 'sigmoid'))\n",
    "ann.add(tf.keras.layers.Dense(units=22, activation= 'relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=11, activation= 'relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=1))\n",
    "ann.compile(optimizer=keras.optimizers.Adamax(learning_rate=0.001), loss=\"mean_absolute_error\", metrics=['mean_absolute_error'])\n",
    "history = ann.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[keras.callbacks.EarlyStopping( monitor=\"val_loss\", patience=100, mode=\"min\", restore_best_weights=True),tensorboard_cb],batch_size=32, epochs=5000, verbose=0)\n",
    "\n",
    "\n",
    "y_pred_test = ann.predict(X_test)\n",
    "y_pred_train = ann.predict(X_train)\n",
    "\n",
    "print(Ion, \"Training\", \"R2 =\", round(r2_score(y_train, y_pred_train), ndigits=2), \"  MAE =\", round(mean_absolute_error(\n",
    "    y_train, y_pred_train), ndigits=2), \"  MSE =\", round(mean_squared_error(y_train, y_pred_train), ndigits=2))\n",
    "print(Ion, \"Test    \", \"R2 =\", round(r2_score(y_test, y_pred_test), ndigits=2),  \"  MAE =\", round(mean_absolute_error(\n",
    "    y_test, y_pred_test), ndigits=2),  \"  MSE =\", round(mean_squared_error(y_test, y_pred_test), ndigits=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_ANN = ann.predict(X)\n",
    "dfmerged['ANN'] = y_pred_ANN\n",
    "dfmerged['LR'] = y_pred_LR\n",
    "dfmerged['RT'] = y_pred_RT\n",
    "dfmerged['RF'] = y_pred_RF\n",
    "dfmerged['GB'] = y_pred_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test= train_test_split(dfmerged, test_size=0.2, random_state=1)\n",
    "Train[\"Train|Test\"]='Train'\n",
    "Test[\"Train|Test\"]='Test'\n",
    "dfmerged2=pd.concat([Train,Test])\n",
    "dfmerged2= dfmerged2.loc[:, ['Long Station Name','Collection Date','EC',Ion,'Sacramento X2','Location','WYT','Data','month','year', 'ANN','LR','RT','RF','GB','Train|Test']]\n",
    "#dfmerged2.sort_values('Collection Date')\n",
    "dfmerged2.to_csv(f'Output/{Ion}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Train')\n",
    "# print('MLR:', 'R2:',round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['LR']), ndigits=2), \"  MAE =\", round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['LR']), ndigits=2), \" MSE =\", round(mean_squared_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['LR']), ndigits=2))\n",
    "# print('RT:', ' R2:',round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['RT']), ndigits=2), \"  MAE =\", round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['RT']), ndigits=2), \"  MSE =\", round(mean_squared_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['RT']), ndigits=2))\n",
    "# print('RF:', ' R2:',round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['RF']), ndigits=2), \"  MAE =\", round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['RF']), ndigits=2), \"  MSE =\", round(mean_squared_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['RF']), ndigits=2))\n",
    "# print('GB:', ' R2:',round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['GB']), ndigits=2), \"  MAE =\", round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['GB']), ndigits=2), \"   MSE =\", round(mean_squared_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['GB']), ndigits=2))\n",
    "# print('ANN:', 'R2:',round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['ANN']), ndigits=2), \"  MAE =\", round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['ANN']), ndigits=2), \"  MSE =\", round(mean_squared_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['ANN']), ndigits=2))\n",
    "\n",
    "# print('Test')\n",
    "# print('MLR:', 'R2:',round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['LR']), ndigits=2), \"  MAE =\", round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['LR']), ndigits=2), \" MSE =\", round(mean_squared_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['LR']), ndigits=2))\n",
    "# print('RT:', ' R2:',round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['RT']), ndigits=2), \"   MAE =\", round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['RT']), ndigits=2), \"  MSE =\", round(mean_squared_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['RT']), ndigits=2))\n",
    "# print('RF:', ' R2:',round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['RF']), ndigits=2), \"   MAE =\", round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['RF']), ndigits=2), \"  MSE =\", round(mean_squared_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['RF']), ndigits=2))\n",
    "# print('GB:', ' R2:',round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['GB']), ndigits=2), \"  MAE =\", round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['GB']), ndigits=2), \"  MSE =\", round(mean_squared_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['GB']), ndigits=2))\n",
    "# print('ANN:', 'R2:',round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['ANN']), ndigits=2), \"   MAE =\", round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['ANN']), ndigits=2), \"  MSE =\", round(mean_squared_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['ANN']), ndigits=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_R2</th>\n",
       "      <th>Train_MAE</th>\n",
       "      <th>Test_R2</th>\n",
       "      <th>Test_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLR</th>\n",
       "      <td>0.76</td>\n",
       "      <td>10.74</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RT</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.93</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>6.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANN</th>\n",
       "      <td>0.93</td>\n",
       "      <td>4.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Train_R2 Train_MAE Test_R2 Test_MAE\n",
       "MLR     0.76     10.74    0.65    10.84\n",
       "RT      0.95      4.61     0.8     8.51\n",
       "GB      0.93       5.4    0.86     7.33\n",
       "RF      0.95       4.2    0.86     6.88\n",
       "ANN     0.93      4.77    0.86     7.32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Performance= pd.DataFrame(index=[\"MLR\", \"RT\", \"GB\",\"RF\",\"ANN\"],columns=['Train_R2','Train_MAE','Test_R2',\"Test_MAE\"])\n",
    "Performance.loc[\"MLR\"][\"Train_R2\"]=round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['LR']), ndigits=2)\n",
    "Performance.loc[\"RT\"][\"Train_R2\"]=round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['RT']), ndigits=2)\n",
    "Performance.loc[\"GB\"][\"Train_R2\"]=round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['GB']), ndigits=2)\n",
    "Performance.loc[\"RF\"][\"Train_R2\"]=round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['RF']), ndigits=2)\n",
    "Performance.loc[\"ANN\"][\"Train_R2\"]=round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['ANN']), ndigits=2)\n",
    "\n",
    "Performance.loc[\"MLR\"][\"Train_MAE\"]=round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['LR']), ndigits=2)\n",
    "Performance.loc[\"RT\"][\"Train_MAE\"]=round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['RT']), ndigits=2)\n",
    "Performance.loc[\"GB\"][\"Train_MAE\"]=round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['GB']), ndigits=2)\n",
    "Performance.loc[\"RF\"][\"Train_MAE\"]=round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['RF']), ndigits=2)\n",
    "Performance.loc[\"ANN\"][\"Train_MAE\"]=round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Train\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Train\"]['ANN']), ndigits=2)\n",
    "\n",
    "Performance.loc[\"MLR\"][\"Test_MAE\"]=round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['LR']), ndigits=2)\n",
    "Performance.loc[\"RT\"][\"Test_MAE\"]=round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['RT']), ndigits=2)\n",
    "Performance.loc[\"GB\"][\"Test_MAE\"]=round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['GB']), ndigits=2)\n",
    "Performance.loc[\"RF\"][\"Test_MAE\"]=round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['RF']), ndigits=2)\n",
    "Performance.loc[\"ANN\"][\"Test_MAE\"]=round(mean_absolute_error(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['ANN']), ndigits=2)\n",
    "\n",
    "Performance.loc[\"MLR\"][\"Test_R2\"]=round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['LR']), ndigits=2)\n",
    "Performance.loc[\"RT\"][\"Test_R2\"]=round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['RT']), ndigits=2)\n",
    "Performance.loc[\"GB\"][\"Test_R2\"]=round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['GB']), ndigits=2)\n",
    "Performance.loc[\"RF\"][\"Test_R2\"]=round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['RF']), ndigits=2)\n",
    "Performance.loc[\"ANN\"][\"Test_R2\"]=round(r2_score(dfmerged2[dfmerged2['Train|Test']==\"Test\"][Ion], dfmerged2[dfmerged2['Train|Test']==\"Test\"]['ANN']), ndigits=2)\n",
    "Performance.to_csv(\"Performance.csv\")\n",
    "Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models/col_names.pkl']"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.save(f'Models/ANN_{Ion}.h5')\n",
    "import joblib\n",
    "joblib.dump(regressorLinear,f'Models/MLR_{Ion}.pkl')\n",
    "joblib.dump(regressorTree,f'Models/RT_{Ion}.pkl')\n",
    "joblib.dump(regressorRF,f'Models/RF_{Ion}.pkl')\n",
    "joblib.dump(regressorGB,f'Models/GB_{Ion}.pkl')\n",
    "\n",
    "joblib.dump(list(X.columns),f'Models/col_names.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold cross validation\n",
    "\n",
    "k=5 in this case (kinda same as the 0.2 setting above)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 1068 TEST: 268\n",
      "Random Forest:\n",
      "         Training R2 = 0.96   MAE = 0.73   MSE = 3.09\n",
      "         Test     R2 = 0.95   MAE = 0.95   MSE = 3.63\n",
      "TRAIN: 1069 TEST: 267\n",
      "Random Forest:\n",
      "         Training R2 = 0.97   MAE = 0.65   MSE = 1.82\n",
      "         Test     R2 = 0.89   MAE = 1.12   MSE = 9.44\n",
      "TRAIN: 1069 TEST: 267\n",
      "Random Forest:\n",
      "         Training R2 = 0.96   MAE = 0.73   MSE = 2.92\n",
      "         Test     R2 = 0.97   MAE = 0.89   MSE = 1.47\n",
      "TRAIN: 1069 TEST: 267\n",
      "Random Forest:\n",
      "         Training R2 = 0.96   MAE = 0.72   MSE = 3.05\n",
      "         Test     R2 = 0.94   MAE = 1.12   MSE = 4.6\n",
      "TRAIN: 1069 TEST: 267\n",
      "Random Forest:\n",
      "         Training R2 = 0.96   MAE = 0.7   MSE = 2.94\n",
      "         Test     R2 = 0.95   MAE = 0.99   MSE = 4.49\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf=KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    regressorRFk = RandomForestRegressor(n_estimators=100, random_state=0, min_samples_leaf=4)\n",
    "    regressorRFk.fit(X_train, y_train)\n",
    "    y_pred_test = regressorRFk.predict(X_test)\n",
    "    y_pred_train = regressorRFk.predict(X_train)\n",
    "    y_pred_RF = regressorRFk.predict(X)\n",
    "    y_pred_test_RF = regressorRFk.predict(X_test)\n",
    "\n",
    "    print(\"Random Forest:\")\n",
    "    print(\"        \", \"Training\", \"R2 =\", round(r2_score(y_train, y_pred_train), ndigits=2), \"  MAE =\", round(\n",
    "        mean_absolute_error(y_train, y_pred_train), ndigits=2), \"  MSE =\", round(mean_squared_error(y_train, y_pred_train), ndigits=2))\n",
    "    print(\"        \", \"Test    \", \"R2 =\", round(r2_score(y_test, y_pred_test), ndigits=2), \"  MAE =\", round(\n",
    "        mean_absolute_error(y_test, y_pred_test), ndigits=2), \"  MSE =\", round(mean_squared_error(y_test, y_pred_test), ndigits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 1068 TEST: 268\n",
      "9/9 [==============================] - 0s 875us/step\n",
      "34/34 [==============================] - 0s 697us/step\n",
      "42/42 [==============================] - 0s 683us/step\n",
      "9/9 [==============================] - 0s 875us/step\n",
      "ANN:\n",
      "         Training R2 = 0.97   MAE = 0.67   MSE = 1.94\n",
      "         Test     R2 = 0.97   MAE = 0.83   MSE = 2.06\n",
      "TRAIN: 1069 TEST: 267\n",
      "9/9 [==============================] - 0s 875us/step\n",
      "34/34 [==============================] - 0s 758us/step\n",
      "42/42 [==============================] - 0s 854us/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "ANN:\n",
      "         Training R2 = 0.99   MAE = 0.56   MSE = 1.02\n",
      "         Test     R2 = 0.95   MAE = 0.95   MSE = 4.57\n",
      "TRAIN: 1069 TEST: 267\n",
      "9/9 [==============================] - 0s 875us/step\n",
      "34/34 [==============================] - 0s 1ms/step\n",
      "42/42 [==============================] - 0s 894us/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "ANN:\n",
      "         Training R2 = 0.96   MAE = 0.75   MSE = 3.51\n",
      "         Test     R2 = 0.98   MAE = 0.79   MSE = 1.1\n",
      "TRAIN: 1069 TEST: 267\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "34/34 [==============================] - 0s 697us/step\n",
      "42/42 [==============================] - 0s 732us/step\n",
      "9/9 [==============================] - 0s 875us/step\n",
      "ANN:\n",
      "         Training R2 = 0.98   MAE = 0.64   MSE = 1.74\n",
      "         Test     R2 = 0.98   MAE = 0.9   MSE = 1.67\n",
      "TRAIN: 1069 TEST: 267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf=KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "KfoldM = pd.DataFrame(columns=['R2_Train', 'MAE_Train','R2_Test', 'MAE_Test'])\n",
    "KFoldR2Test=[]\n",
    "KFoldMAETest=[]\n",
    "KFoldR2Train=[]\n",
    "KFoldMAETrain=[]\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(tf.keras.layers.Dense(units=22))\n",
    "    ann.add(tf.keras.layers.Dense(units=N[0], activation=A[0]))\n",
    "    ann.add(tf.keras.layers.Dense(units=N[1], activation=A[1]))\n",
    "    ann.add(tf.keras.layers.Dense(units=N[2], activation=A[2]))\n",
    "    ann.add(tf.keras.layers.Dense(units=N[3], activation=A[3]))\n",
    "    ann.add(tf.keras.layers.Dense(units=1))\n",
    "    ann.compile(optimizer=keras.optimizers.Adamax(learning_rate=0.001), loss=\"mean_absolute_error\", metrics=['mean_absolute_error'])\n",
    "    history = ann.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[keras.callbacks.EarlyStopping( monitor=\"val_loss\", patience=100, mode=\"min\", restore_best_weights=True),tensorboard_cb],batch_size=32, epochs=5000, verbose=0)\n",
    "    y_pred_test = ann.predict(X_test)\n",
    "    y_pred_train = ann.predict(X_train)\n",
    "    y_pred_ANN = ann.predict(X)\n",
    "    y_pred_test_ANN = ann.predict(X_test)\n",
    "    KFoldR2Test.append(round(r2_score(y_test, y_pred_test), ndigits=2))\n",
    "    KFoldMAETest.append(round(mean_absolute_error(y_test, y_pred_test), ndigits=2))\n",
    "    KFoldR2Train.append(round(r2_score(y_train, y_pred_train), ndigits=2))\n",
    "    KFoldMAETrain.append(round(mean_absolute_error(y_train, y_pred_train), ndigits=2))\n",
    "    print(\"ANN:\")\n",
    "    print(\"        \", \"Training\", \"R2 =\", round(r2_score(y_train, y_pred_train), ndigits=2), \"  MAE =\", round(\n",
    "        mean_absolute_error(y_train, y_pred_train), ndigits=2), \"  MSE =\", round(mean_squared_error(y_train, y_pred_train), ndigits=2))\n",
    "    print(\"        \", \"Test    \", \"R2 =\", round(r2_score(y_test, y_pred_test), ndigits=2), \"  MAE =\", round(\n",
    "        mean_absolute_error(y_test, y_pred_test), ndigits=2), \"  MSE =\", round(mean_squared_error(y_test, y_pred_test), ndigits=2))\n",
    "\n",
    "KFoldR2Test=pd.DataFrame(KFoldR2Test)\n",
    "KFoldMAETest=pd.DataFrame(KFoldMAETest)\n",
    "KFoldR2Train=pd.DataFrame(KFoldR2Train)\n",
    "KFoldMAETrain=pd.DataFrame(KFoldMAETrain)\n",
    "KfoldM[\"R2_Train\"]=KFoldR2Train\n",
    "KfoldM[\"MAE_Train\"]=KFoldMAETrain\n",
    "KfoldM[\"R2_Test\"]=KFoldR2Test\n",
    "KfoldM[\"MAE_Test\"]=KFoldMAETest\n",
    "KfoldM.to_csv(\"Kfold.csv\")\n",
    "KfoldM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ion_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f079ae8466949b74cf7cab44e50ac795bd008a2be4304c17e64eb6497cdff050"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
